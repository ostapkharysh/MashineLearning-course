{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Передбачення зарплат на IT-ринку України"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У цьому завданні ви працюватимете з реальними даними з [зарплатного опитування DOU.ua за травень 2016р](https://dou.ua/lenta/articles/salary-report-may-june-2016/). Ви реалізуєте зважену лінійну регресію, яка передбачає зарплати Java-інженерів, та навчите свою модель за допомогою градієнтного спуску.\n",
    "\n",
    "Заповніть пропущений код в розділі «Моделювання» (позначено коментарями) та запустіть розділ «Тестування», щоб перевірити його правильність."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ipython_unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Підготовка даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salaries = pd.read_csv(\"data/2016_may_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оберемо тільки Java-інженерів з-поміж усіх респондентів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_java = pd.DataFrame(df_salaries[(df_salaries[\"Язык.программирования\"] == \"Java\") &\n",
    "                                   (df_salaries[\"cls\"] == \"DEV\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейменуємо деякі колонки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_java.rename(\n",
    "    columns={\n",
    "        \"exp\": \"TotalExperience\",\n",
    "        \"loc\": \"Location\"\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодуємо рівень англійської мови числами від 1 (найнижчий) до 5 (найвищий):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_java[\"EnglishLevel\"] = df_java[\"Уровень.английского\"].map({\n",
    "    \"элементарный\": 1,\n",
    "    \"ниже среднего\": 2,\n",
    "    \"средний\": 3,\n",
    "    \"выше среднего\": 4,\n",
    "    \"продвинутый\": 5\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодуємо колонку Location (найбільші IT-міста або \"other\") за допомогою one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_columns = [\n",
    "    \"LocationOther\",\n",
    "    \"LocationDnipro\",\n",
    "    \"LocationKyiv\",\n",
    "    \"LocationLviv\",\n",
    "    \"LocationOdesa\",\n",
    "    \"LocationKharkiv\"\n",
    "]\n",
    "df_java[city_columns] = pd.get_dummies(df_java[\"Location\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Відберемо такі ознаки:\n",
    "\n",
    "* Загальна кількість років досвіду\n",
    "* Рівень англійської мови\n",
    "* Місто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\"TotalExperience\", \"EnglishLevel\"] + city_columns\n",
    "df_X = df_java[feature_columns]\n",
    "df_y = df_java[[\"salary\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (929, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", df_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalExperience</th>\n",
       "      <th>EnglishLevel</th>\n",
       "      <th>LocationOther</th>\n",
       "      <th>LocationDnipro</th>\n",
       "      <th>LocationKyiv</th>\n",
       "      <th>LocationLviv</th>\n",
       "      <th>LocationOdesa</th>\n",
       "      <th>LocationKharkiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TotalExperience  EnglishLevel  LocationOther  LocationDnipro  \\\n",
       "5               0.5             3              1               0   \n",
       "7               5.0             1              0               0   \n",
       "17              0.0             3              0               0   \n",
       "27              4.0             3              0               0   \n",
       "28              6.0             4              0               0   \n",
       "39              3.0             4              0               1   \n",
       "46              2.0             4              0               0   \n",
       "49              3.0             3              0               0   \n",
       "59              2.0             3              0               0   \n",
       "89              1.0             5              0               0   \n",
       "\n",
       "    LocationKyiv  LocationLviv  LocationOdesa  LocationKharkiv  \n",
       "5              0             0              0                0  \n",
       "7              1             0              0                0  \n",
       "17             1             0              0                0  \n",
       "27             1             0              0                0  \n",
       "28             1             0              0                0  \n",
       "39             0             0              0                0  \n",
       "46             0             0              0                1  \n",
       "49             1             0              0                0  \n",
       "59             0             0              0                1  \n",
       "89             1             0              0                0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    salary\n",
       "5      500\n",
       "7     1600\n",
       "17     600\n",
       "27    3400\n",
       "28    2880\n",
       "39    1425\n",
       "46    1700\n",
       "49    1800\n",
       "59    1235\n",
       "89    1200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розділимо вибірку на навчальну та тестову:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_assignment = np.random.uniform(size=len(df_X))\n",
    "\n",
    "X_train = df_X[dataset_assignment <= training_set_size].values\n",
    "y_train = df_y[dataset_assignment <= training_set_size].values.flatten()\n",
    "\n",
    "X_test = df_X[dataset_assignment > training_set_size].values\n",
    "y_test = df_y[dataset_assignment > training_set_size].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Щоб градієнтний спуск швидше збігався, нормалізуємо навчальну вибірку так, щоб кожна ознака мала $\\mu = 0, \\sigma = 1$:\n",
    "\n",
    "$ x' = \\frac{x - \\bar{x}}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_means = np.average(X_train, axis=0)\n",
    "feature_sigmas = np.std(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - feature_means) / feature_sigmas\n",
    "X_test = (X_test - feature_means) / feature_sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Додаємо уявну ознаку $x_0 = 1$ (intercept term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not np.all(X_train[:, 0] == 1):\n",
    "    X_train = np.insert(X_train, 0, values=1, axis=1)\n",
    "    \n",
    "if not np.all(X_test[:, 0] == 1):\n",
    "    X_test = np.insert(X_test, 0, values=1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train:  (741, 9)\n",
      "y train:  (741,)\n",
      "\n",
      "X test:   (188, 9)\n",
      "y test:   (188,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train: \", X_train.shape)\n",
    "print(\"y train: \", y_train.shape)\n",
    "print()\n",
    "print(\"X test:  \", X_test.shape)\n",
    "print(\"y test:  \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Моделювання"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте функцію гіпотези лінійної регресії в матричній формі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_linear(theta, X):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Compute the hypothesis function for linear regression.\n",
    "    \"\"\"\n",
    "   vector = []\n",
    "    result = 0\n",
    "    if isinstance(X[0].tolist(), list):\n",
    "        for i in range(len(X)):\n",
    "            result = 0\n",
    "            for el in range(len(theta)):\n",
    "                result += theta[el] * X[i][el]\n",
    "            vector.append(result)\n",
    "        return vector\n",
    "    else:\n",
    "        result = 0\n",
    "        for z in range(len(theta)):\n",
    "            result += theta[z] * X[z]\n",
    "        return result\n",
    "     \"\"\"\n",
    "    \n",
    "    return np.dot(X, theta)\n",
    "    # ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте функцію зважування всіх навчальних прикладів $x^{(i)}$, якщо нам дана точка передбачення $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_example_weights(X, x_pred, tau):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Compute the weight for each example, given the\n",
    "    # prediction point (x_pred).\n",
    "    weights = np.array([np.exp(np.sum(i)) for i in np.power(np.subtract(X, x_pred), 2) / (-2 * tau * tau)])\n",
    "    # ====================================================\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте функцію втрат зваженої лінійної регресії. Подумайте, як обчислити цей вираз відразу в матричному вигляді."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(theta, X, y, weights):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Given the currently learned model weights (theta),\n",
    "    # compute the overall loss on the training set (X),\n",
    "    # taking the weights into account.\n",
    "    m = len(y)\n",
    "    pred = np.dot(X, theta)\n",
    "    sq_error = weights*(pred-y)*(pred - y)\n",
    "    j = np.sum(sq_error)/2/m\n",
    "    \n",
    "    return j\n",
    "    # ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте обчислення градієнта функції втрат зваженої лінійної регресії. Подумайте, як обчислити цей вираз відразу в матричному вигляді."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_gradient(theta, X, y, weights):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Given the currently learned model weights (theta),\n",
    "    # compute the gradient of the cost function on the\n",
    "    # training set (X), taking the weights into account.\n",
    "    pred = np.dot(X,theta)\n",
    "    \n",
    "    return np.dot(weights*(pred-y), X)\n",
    "    # ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте один крок градієнтного спуску."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_weights(theta, learning_rate, cost_gradient):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Given the learning rate and the gradient of the\n",
    "    # cost function, take one gradient descent step and\n",
    "    # return the updated vector theta.\n",
    "    \n",
    "    return np.subtract(theta,learning_rate*cost_gradient)\n",
    "    # ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Навчаємо модель:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, weights, loss_fun, grad_fun, learning_rate, convergence_threshold, max_iters, verbose=False):\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    losses = []\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        loss = loss_fun(theta, X, y, weights)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Iteration: {0:3} Loss: {1}\".format(i + 1, loss))\n",
    "\n",
    "        if len(losses) > 2 and np.abs(losses[-1] - losses[-2]) <= convergence_threshold:\n",
    "            break\n",
    "        \n",
    "        grad = grad_fun(theta, X, y, weights)\n",
    "        theta = update_model_weights(theta, learning_rate, grad)\n",
    "        \n",
    "    return theta, np.array(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Передбачення нових даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_weighted_linear(X, y, x_pred, verbose=False):\n",
    "    weights = get_example_weights(X, x_pred, tau=0.1)\n",
    "    theta, losses = gradient_descent(\n",
    "        X,\n",
    "        y,\n",
    "        weights,\n",
    "        loss_fun=cost_function,\n",
    "        grad_fun=cost_function_gradient,\n",
    "        learning_rate=0.005,\n",
    "        convergence_threshold=0.0001,\n",
    "        max_iters=500,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    return predict_linear(theta, x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = X_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:   1 Loss: 2051.2757624241217\n",
      "Iteration:   2 Loss: 1513.80754533939\n",
      "Iteration:   3 Loss: 1121.5661412085208\n",
      "Iteration:   4 Loss: 835.3104813807901\n",
      "Iteration:   5 Loss: 626.4026457393462\n",
      "Iteration:   6 Loss: 473.9428347420583\n",
      "Iteration:   7 Loss: 362.6784874795104\n",
      "Iteration:   8 Loss: 281.47836731823753\n",
      "Iteration:   9 Loss: 222.2189578385353\n",
      "Iteration:  10 Loss: 178.97176060000322\n",
      "Iteration:  11 Loss: 147.41018943700507\n",
      "Iteration:  12 Loss: 124.37672511648809\n",
      "Iteration:  13 Loss: 107.56702714333434\n",
      "Iteration:  14 Loss: 95.29940026075593\n",
      "Iteration:  15 Loss: 86.3465523464754\n",
      "Iteration:  16 Loss: 79.81281223336279\n",
      "Iteration:  17 Loss: 75.04452393759323\n",
      "Iteration:  18 Loss: 71.56465284995902\n",
      "Iteration:  19 Loss: 69.02506168722135\n",
      "Iteration:  20 Loss: 67.17168173897294\n",
      "Iteration:  21 Loss: 65.81909503156993\n",
      "Iteration:  22 Loss: 64.83198452854963\n",
      "Iteration:  23 Loss: 64.11159658700912\n",
      "Iteration:  24 Loss: 63.58586133133228\n",
      "Iteration:  25 Loss: 63.20218255525631\n",
      "Iteration:  26 Loss: 62.9221758313128\n",
      "Iteration:  27 Loss: 62.7178284114965\n",
      "Iteration:  28 Loss: 62.568696743498265\n",
      "Iteration:  29 Loss: 62.45986123317698\n",
      "Iteration:  30 Loss: 62.380433641249596\n",
      "Iteration:  31 Loss: 62.322467789451316\n",
      "Iteration:  32 Loss: 62.28016459977012\n",
      "Iteration:  33 Loss: 62.24929193637045\n",
      "Iteration:  34 Loss: 62.22676120936045\n",
      "Iteration:  35 Loss: 62.210318382506195\n",
      "Iteration:  36 Loss: 62.19831847232921\n",
      "Iteration:  37 Loss: 62.18956097876488\n",
      "Iteration:  38 Loss: 62.18316978334519\n",
      "Iteration:  39 Loss: 62.17850549954057\n",
      "Iteration:  40 Loss: 62.17510150651256\n",
      "Iteration:  41 Loss: 62.17261726689159\n",
      "Iteration:  42 Loss: 62.170804258343196\n",
      "Iteration:  43 Loss: 62.16948111060899\n",
      "Iteration:  44 Loss: 62.1685154606533\n",
      "Iteration:  45 Loss: 62.16781071064698\n",
      "Iteration:  46 Loss: 62.167296364015726\n",
      "Iteration:  47 Loss: 62.16692097274003\n",
      "Iteration:  48 Loss: 62.16664699033295\n",
      "Iteration:  49 Loss: 62.166447015570974\n",
      "Iteration:  50 Loss: 62.166301051188995\n",
      "Iteration:  51 Loss: 62.166194503290946\n",
      "Iteration:  52 Loss: 62.166116721330184\n"
     ]
    }
   ],
   "source": [
    "predicted = predict_weighted_linear(X_train, y_train, x_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцінимо, наскільки модель помиляється на тестовій вибірці:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.array([predict_weighted_linear(X_test, y_test, X_test[i]) for i in range(len(y_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_residuals = pd.DataFrame(y_test - y_test_pred, columns=[\"residual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5,1,'Error Distribution')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0da6b17f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0d81bba20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df_residuals.plot.bar(figsize=(10, 5))\n",
    "ax.legend().remove()\n",
    "ax.get_xaxis().set(ticklabels=[])\n",
    "ax.set(xlabel=\"Example #\")\n",
    "ax.set(ylabel=\"Prediction Error, $\")\n",
    "ax.set(title=\"Residuals\")\n",
    "\n",
    "bins = np.arange(-3000, 3001, 100)\n",
    "ticks = np.arange(-3000, 3001, 500)\n",
    "\n",
    "ax = df_residuals.hist(bins=bins, figsize=(10, 5))[0][0]\n",
    "ax.set(xticks=ticks)\n",
    "ax.set(xlabel=\"Prediction Error, $\")\n",
    "ax.set(ylabel=\"Frequency\")\n",
    "ax.set(title=\"Error Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестування"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустіть комірку нижче, щоб перевірити правильність вашого коду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/unittest.status+json": {
       "color": "yellow",
       "message": "",
       "previous": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/unittest.status+json": {
       "color": "lightgreen",
       "message": "............\n----------------------------------------------------------------------\nRan 12 tests in 0.004s\n\nOK\n",
       "previous": 0
      },
      "text/plain": [
       "Success"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............\n",
      "----------------------------------------------------------------------\n",
      "Ran 12 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=12 errors=0 failures=0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%unittest_main\n",
    "\n",
    "class WLRTests(unittest.TestCase):\n",
    "\n",
    "    x = np.array([1, -0.5, 3, 1])\n",
    "    X = np.array([\n",
    "        [1, -0.5, 3, 1],\n",
    "        [2, 8, -0.33, 5],\n",
    "        [0, 0, 0, 0]\n",
    "    ])\n",
    "    y = np.array([40, 100, 12])\n",
    "    theta = np.array([2, 5, 7, 9])\n",
    "    eps = 0.001\n",
    "\n",
    "    def assertFloatEquals(self, a, b):\n",
    "        self.assertTrue(np.abs(a - b) < self.eps)\n",
    "    \n",
    "    def assertArrayEquals(self, a, b):\n",
    "        a = np.array(a)\n",
    "        b = np.array(b)\n",
    "        self.assertEqual(a.shape, b.shape)\n",
    "        self.assertTrue(np.all(np.abs(a - b) < self.eps))\n",
    "    \n",
    "    def test_predict_linear_should_compute_correct_prediction_for_1_example(self):\n",
    "        expected = 29.5\n",
    "        actual = predict_linear(self.theta, self.x)\n",
    "        self.assertEqual(actual, expected)\n",
    "    \n",
    "    def test_predict_linear_should_compute_correct_predictions_for_multiple_examples(self):\n",
    "        expected = [29.5, 86.69, 0]\n",
    "        actual = (predict_linear(self.theta, self.X))\n",
    "        self.assertArrayEquals(actual, expected)\n",
    "    \n",
    "    def test_get_example_weights_should_return_properly_shaped_vector(self):\n",
    "        weights = get_example_weights(self.X, self.x, tau=5)\n",
    "        self.assertTrue(weights.shape[0] == self.X.shape[0])\n",
    "    \n",
    "    def test_get_example_weights_should_compute_correct_weights(self):\n",
    "        expected = [1.000, 0.134, 0.798]\n",
    "        actual = get_example_weights(self.X, self.x, tau=5)\n",
    "        self.assertArrayEquals(actual, expected)\n",
    "    \n",
    "    def test_cost_function_should_compute_correct_cost_unweighted(self):\n",
    "        weights = np.ones(self.X.shape[0])\n",
    "        expected = 71.901\n",
    "        actual = cost_function(self.theta, self.X, self.y, weights)\n",
    "        self.assertFloatEquals(actual, expected)\n",
    "    \n",
    "    def test_cost_function_should_compute_correct_cost_weighted(self):\n",
    "        weights = np.array([0.5, 0.1, 0.28])\n",
    "        expected = 18.860\n",
    "        actual = cost_function(self.theta, self.X, self.y, weights)\n",
    "        self.assertFloatEquals(actual, expected)\n",
    "\n",
    "    def test_cost_gradient_should_return_properly_shaped_vector(self):\n",
    "        weights = np.ones(self.X.shape[0])\n",
    "        grad = cost_function_gradient(self.theta, self.X, self.y, weights)\n",
    "        self.assertTrue(grad.shape == self.theta.shape)\n",
    "        \n",
    "    def test_cost_gradient_should_compute_correct_gradient_unweighted(self):\n",
    "        weights = np.ones(self.X.shape[0])\n",
    "        expected = [-37.12, -101.23, -27.108, -77.05]\n",
    "        actual = cost_function_gradient(self.theta, self.X, self.y, weights)\n",
    "        self.assertArrayEquals(actual, expected)\n",
    "    \n",
    "    def test_cost_gradient_should_compute_correct_gradient_weighted(self):\n",
    "        weights = np.array([0.5, 0.1, 0.28])\n",
    "        expected = [-7.912, -8.023, -15.311, -11.905]\n",
    "        actual = cost_function_gradient(self.theta, self.X, self.y, weights)\n",
    "        self.assertArrayEquals(actual, expected)\n",
    "    \n",
    "    def test_update_model_weights_should_not_update_when_gradient_is_zero(self):\n",
    "        grad = np.zeros(self.theta.shape[0])\n",
    "        theta_new = update_model_weights(self.theta, learning_rate=1, cost_gradient=grad)\n",
    "        self.assertArrayEquals(theta_new, self.theta)\n",
    "    \n",
    "    def test_update_model_weights_should_update_with_complete_gradient_if_learning_rate_is_one(self):\n",
    "        grad = np.array([1.35, -0.89, 0.16, 0.98])\n",
    "        expected = [0.65, 5.89, 6.84, 8.02]\n",
    "        actual = update_model_weights(self.theta, learning_rate=1, cost_gradient=grad)\n",
    "        self.assertArrayEquals(actual, expected)\n",
    "    \n",
    "    def test_update_model_weights_should_take_learning_rate_into_account(self):\n",
    "        grad = np.array([1.35, -0.89, 0.16, 0.98])\n",
    "        expected = [1.730, 5.178, 6.968, 8.804]\n",
    "        actual = update_model_weights(self.theta, learning_rate=0.2, cost_gradient=grad)\n",
    "        self.assertArrayEquals(actual, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
